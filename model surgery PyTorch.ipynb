{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "fcdfb5e4d63446479b387ccc6bba57b2",
      "8334d2d7401a4b3da1f1437e0b81be80",
      "5defa6b8866e415697ac3afe2ca5a015",
      "14be4aef783d4555a52b2d2463f9ca87",
      "130b91bd8c14468599dd83dcbb67c1ad",
      "8265ee2c116444d6a288523f0ac49938",
      "71bf404c05af4a54a37c594345d33675",
      "a3882073ab3d4927b82c8be9c58915ae",
      "8b4443c5778b41fe99c157174120133b",
      "9c1b2b1a3e3247d38a3082b37c3d105f",
      "aa8a8f4e8d964c40b35d91a36f7ddb18"
     ]
    },
    "executionInfo": {
     "elapsed": 8183,
     "status": "ok",
     "timestamp": 1633331056916,
     "user": {
      "displayName": "sarah el-sherif",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZb-iYNW9oBp8yKb9k32GPw733XSv_hms_MwNSIw=s64",
      "userId": "15385911606173447697"
     },
     "user_tz": -180
    },
    "id": "ZepGSZtzzbSg",
    "outputId": "45d71212-baa7-4056-89a6-4e90bc68cfaf"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torchvision==0.11.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define ResNet model structure\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from torch import Tensor\n",
    "#from ..utils import _log_api_usage_once\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError(\"BasicBlock only supports groups=1 and base_width=64\")\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion: int = 4\n",
    "    def __init__(\n",
    "        self,\n",
    "        inplanes: int,\n",
    "        planes: int,\n",
    "        stride: int = 1,\n",
    "        downsample: Optional[nn.Module] = None,\n",
    "        groups: int = 1,\n",
    "        base_width: int = 64,\n",
    "        dilation: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.0)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "       \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "       # print(out.shape)\n",
    "        return out\n",
    "#-----------------------------------------------------------------------------------------------------------\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 1000,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "       # _log_api_usage_once(self)\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\n",
    "                \"replace_stride_with_dilation should be None \"\n",
    "                \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation)\n",
    "            )\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1,\n",
    "        dilate: bool = False,\n",
    "    ) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes, planes, stride, downsample, \n",
    "                self.groups, self.base_width, previous_dilation, norm_layer\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.inplanes,\n",
    "                    planes,\n",
    "                    groups=self.groups,\n",
    "                    base_width=self.base_width,\n",
    "                    dilation=self.dilation,\n",
    "                    norm_layer=norm_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "    \n",
    "def _resnet(\n",
    "    #arch: str,\n",
    "    block: Type[Union[BasicBlock, Bottleneck]],layers: List[int], pretrained: bool,progress: bool,\n",
    "    **kwargs: Any,) -> ResNet:\n",
    "    model = ResNet(block, layers, **kwargs)\n",
    "    PATH =  \"/notebooks/storage/resnet101-63fe2227.pth\" #\"resnet101-5d3b4d8f.pth\"\n",
    "    model.load_state_dict(torch.load(PATH), strict=False)     \n",
    "    return model\n",
    "\n",
    "def resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet:\n",
    "      return _resnet(Bottleneck, [3, 4, 23, 3], pretrained ,progress, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET layer 4 customized backbone ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_layer4(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        layers: List[int],\n",
    "        num_classes: int = 1000,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        \n",
    "    ) -> None:\n",
    "        super(ResNet_layer4, self).__init__()\n",
    "       # _log_api_usage_once(self)\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\n",
    "                \"replace_stride_with_dilation should be None \"\n",
    "                \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation)\n",
    "            )\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer (block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
    "       # self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "       # self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)  # type: ignore[arg-type]\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    " \n",
    "    def _make_layer(\n",
    "        self,\n",
    "        block: Type[Union[BasicBlock, Bottleneck]],\n",
    "        planes: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1,\n",
    "        dilate: bool = False,\n",
    "    ) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "       #     print(\"after if dilate cond: dil, stride\",self.dilation,stride)\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "       # print(\"dil, stride, prev_dil\",self.dilation,stride,previous_dilation)\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes, planes, stride, downsample, \n",
    "                self.groups, self.base_width, previous_dilation, norm_layer\n",
    "            )\n",
    "        )\n",
    "       # print(\"b=0, previous_dil\", previous_dilation)\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for b in range(1, blocks):    \n",
    "            layers.append(\n",
    "                block(\n",
    "                    self.inplanes,\n",
    "                    planes,\n",
    "                    groups=self.groups,\n",
    "                    base_width=self.base_width,\n",
    "                    dilation=self.dilation,\n",
    "                    norm_layer=norm_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "      #  x = self.avgpool(x)\n",
    "      #  x = torch.flatten(x, 1)\n",
    "      #  x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bck_resnet(\n",
    "    block: Type[Union[BasicBlock, Bottleneck]],layers: List[int], pretrained: bool,progress: bool,\n",
    "    **kwargs: Any,) -> ResNet_layer4:\n",
    "    \n",
    "    model = ResNet_layer4(block, layers, **kwargs)\n",
    "    PATH =  \"/notebooks/storage/resnet101-63fe2227.pth\" #\"resnet101-5d3b4d8f.pth\"\n",
    "    model.load_state_dict(torch.load(PATH), strict=False)        \n",
    "    return model\n",
    "\n",
    "def backbone_resnet101(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> ResNet_layer4:\n",
    "    return bck_resnet(Bottleneck, [3, 4, 23, 3], pretrained, progress, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bck_model= backbone_resnet101(pretrained=False , replace_stride_with_dilation=[False, True, True])\n",
    "params = []\n",
    "#for param in bck_model.parameters():\n",
    "   # params.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 1605,
     "status": "ok",
     "timestamp": 1633332043680,
     "user": {
      "displayName": "sarah el-sherif",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZb-iYNW9oBp8yKb9k32GPw733XSv_hms_MwNSIw=s64",
      "userId": "15385911606173447697"
     },
     "user_tz": -180
    },
    "id": "BLOTnnvczdnf",
    "outputId": "8222ee66-c795-442b-9412-92ab867f2050"
   },
   "outputs": [],
   "source": [
    "#read and display image \n",
    "img = Image.open('/notebooks/storage/data/cat1.jpg','r')\n",
    "plt.imshow(img); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict\n",
    "from collections import OrderedDict\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class _SimpleSegmentationModel(nn.Module):\n",
    "    __constants__ = [\"aux_classifier\"]\n",
    "\n",
    "    def __init__(self, backbone: nn.Module, classifier: nn.Module) -> None:\n",
    "        super(_SimpleSegmentationModel, self).__init__()\n",
    "        self.backbone = backbone.eval()\n",
    "        self.classifier = classifier.eval()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Dict[str, Tensor]:\n",
    "        input_shape = x.shape[-2:]\n",
    "        features = self.backbone(x)\n",
    "        result = OrderedDict() \n",
    "        x=features\n",
    "        x = self.classifier(x)\n",
    "        x = F.interpolate(x, size=input_shape, mode=\"bilinear\", align_corners=False)\n",
    "        result= x\n",
    " \n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_weights(model):\n",
    "    resnet101_coco =\"/notebooks/storage/fcn_resnet101_coco-7ecb50ca.pth\" \n",
    "    model.load_state_dict(torch.load(resnet101_coco), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(_SimpleSegmentationModel):    \n",
    "    \"\"\"\n",
    "    Implements a Fully-Convolutional Network for semantic segmentation.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class FCNHead(nn.Sequential):\n",
    "    def __init__(self, in_channels: int, channels: int) -> None:\n",
    "        inter_channels = in_channels // 4\n",
    "        \n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, inter_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(inter_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(inter_channels, channels, 1),\n",
    "        ]\n",
    "\n",
    "        super(FCNHead, self).__init__(*layers)\n",
    "\n",
    "def _fcn_resnet(\n",
    "    num_classes: int,\n",
    "    aux: Optional[bool],\n",
    ") -> FCN:\n",
    "    backbone_l4= backbone_resnet101(pretrained=False , replace_stride_with_dilation=[False, True, True]) #bck layer4  \n",
    "    classifier = FCNHead(2048, num_classes)\n",
    "\n",
    "    return FCN(backbone_l4, classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn_resnet101(\n",
    "    pretrained: bool = False,\n",
    "    progress: bool = True,\n",
    "    num_classes: int = 21,\n",
    "    aux_loss: Optional[bool] = None,\n",
    "    pretrained_backbone: bool = True,\n",
    ") -> FCN:  \n",
    "    \"\"\"Constructs a Fully-Convolutional Network model with a ResNet-101 backbone.\n",
    "    \"\"\"\n",
    "    model = _fcn_resnet(num_classes, aux_loss)\n",
    "    _load_weights(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1633332073559,
     "user": {
      "displayName": "sarah el-sherif",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZb-iYNW9oBp8yKb9k32GPw733XSv_hms_MwNSIw=s64",
      "userId": "15385911606173447697"
     },
     "user_tz": -180
    },
    "id": "ZYNC_Zye9tyQ"
   },
   "outputs": [],
   "source": [
    "# Define the helper function\n",
    "def decode_segmap(image, nc=21):\n",
    "   \n",
    "    label_colors = np.array([(0, 0, 0),  # 0=background\n",
    "                    # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n",
    "                    (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128),\n",
    "                    # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n",
    "                    (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),\n",
    "                    # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person\n",
    "                    (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),\n",
    "                    # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n",
    "                    (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])\n",
    "\n",
    "    r = np.zeros_like(image).astype(np.uint8)\n",
    "    g = np.zeros_like(image).astype(np.uint8)\n",
    "    b = np.zeros_like(image).astype(np.uint8)\n",
    "    \n",
    "    for l in range(0, nc):\n",
    "        idx = image == l\n",
    "        r[idx] = label_colors[l, 0]\n",
    "        g[idx] = label_colors[l, 1]\n",
    "        b[idx] = label_colors[l, 2]\n",
    "    \n",
    "    rgb = np.stack([r, g, b], axis=2)\n",
    "    return rgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Image transformations ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 714,
     "status": "ok",
     "timestamp": 1633332078287,
     "user": {
      "displayName": "sarah el-sherif",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZb-iYNW9oBp8yKb9k32GPw733XSv_hms_MwNSIw=s64",
      "userId": "15385911606173447697"
     },
     "user_tz": -180
    },
    "id": "Yq6hKDvS4PRc"
   },
   "outputs": [],
   "source": [
    "# Apply the transformations\n",
    "preprocess = T.Compose([T.Resize((224,224)),\n",
    "                T.ToTensor(),T.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])])\n",
    "inp_img_tensor = preprocess(img)\n",
    "inp_batch= torch.unsqueeze(inp_img_tensor,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_batch= inp_batch.cuda()\n",
    "print(inp_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#running pretrained resnet model\n",
    "fcn = fcn_resnet101(pretrained=True)\n",
    "fcn= fcn.cuda()\n",
    "fcn.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#run model on img batch\n",
    "out = fcn(inp_batch)\n",
    "print('Output shape:',out.shape) #([1, 21, 224, 224])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om = torch.argmax(out.squeeze(), dim=0).detach().cpu().numpy()\n",
    "print (om.shape) #print (np.unique(om))\n",
    "rgb = decode_segmap(om)\n",
    "plt.imshow(rgb); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image's Classification ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Image's classification -------------\n",
    "modell=resnet101(pretrained= True).eval()\n",
    "modell=modell.cuda()\n",
    "out=modell(inp_batch)\n",
    "#print(out)\n",
    "with open('/notebooks/storage/imagenet_classes2.txt') as f: # path to the ImageNet labels\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "_, index = torch.max(out, 1)\n",
    "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
    "\n",
    "print(classes[index[0]], percentage[index[0]].item())\n",
    "_, indices = torch.sort(out, descending=True)\n",
    "[(classes[idx], percentage[idx].item()) for idx in indices[0][:5]] #top 5 classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPWzqizTuVq1tV6QDt+Qoen",
   "collapsed_sections": [],
   "name": "Human body segmentation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "130b91bd8c14468599dd83dcbb67c1ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa8a8f4e8d964c40b35d91a36f7ddb18",
      "placeholder": "​",
      "style": "IPY_MODEL_9c1b2b1a3e3247d38a3082b37c3d105f",
      "value": " 208M/208M [00:02&lt;00:00, 100MB/s]"
     }
    },
    "14be4aef783d4555a52b2d2463f9ca87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b4443c5778b41fe99c157174120133b",
      "max": 217800805,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3882073ab3d4927b82c8be9c58915ae",
      "value": 217800805
     }
    },
    "5defa6b8866e415697ac3afe2ca5a015": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71bf404c05af4a54a37c594345d33675",
      "placeholder": "​",
      "style": "IPY_MODEL_8265ee2c116444d6a288523f0ac49938",
      "value": "100%"
     }
    },
    "71bf404c05af4a54a37c594345d33675": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8265ee2c116444d6a288523f0ac49938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8334d2d7401a4b3da1f1437e0b81be80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b4443c5778b41fe99c157174120133b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c1b2b1a3e3247d38a3082b37c3d105f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a3882073ab3d4927b82c8be9c58915ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "aa8a8f4e8d964c40b35d91a36f7ddb18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcdfb5e4d63446479b387ccc6bba57b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5defa6b8866e415697ac3afe2ca5a015",
       "IPY_MODEL_14be4aef783d4555a52b2d2463f9ca87",
       "IPY_MODEL_130b91bd8c14468599dd83dcbb67c1ad"
      ],
      "layout": "IPY_MODEL_8334d2d7401a4b3da1f1437e0b81be80"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
